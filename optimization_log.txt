
======================================================================
ADVANCED BODY WEIGHT ESTIMATION - OPTIMIZATION & EXPLAINABILITY
======================================================================

üéØ Goal: Beat research paper baseline (13.5kg MAE)
üíæ Hardware: Mac 8GB RAM (Memory-optimized)
üìä Dataset: ~70,000 samples with 9 facial ratios

======================================================================
======================================================================
STEP 1: MEMORY-EFFICIENT DATA LOADING
======================================================================

Loading /Users/suryayalavarthi/Downloads/Bodyweight Predication/idoc_weight_estimation/facial_features_ratios_V2.csv...
  ‚úì Loaded 66,866 facial feature records
  Memory usage: 8.61 MB

Loading /Users/suryayalavarthi/Downloads/Bodyweight Predication/idoc_weight_estimation/data/raw_images/archive/labels_utf8.csv...
  ‚úì Loaded 69,827 label records
  ‚úì Renamed 'ID' column to 'filename' for merge

Merging datasets on 'filename'...
  ‚úì Merged dataset: 66,866 samples

Parsing weight values...
  ‚úì Parsed weight values from 'Weight' column
  ‚úì Weight range: 17 - 553 lbs

Cleaning data...
  ‚úì Dropped 142 rows with NaN values
  ‚úì Clean dataset: 66,724 samples

üîß MEMORY OPTIMIZATION: Downcasting float64 ‚Üí float32...
  Before: 39.37 MB
  After:  36.82 MB
  ‚úì Saved 2.55 MB (6.5% reduction)

======================================================================
STEP 2: TRAIN-TEST SPLIT
======================================================================

Feature matrix: (66724, 9)
Target vector: (66724,)
Feature columns (9 facial ratios): ['left_eyebrow_ratio', 'right_eyebrow_ratio', 'left_eye_ratio', 'right_eye_ratio', 'nose_width_ratio', 'nose_length_ratio', 'outer_lip_ratio', 'inner_lip_ratio', 'face_height_ratio']

‚úì Training set: 53,379 samples
‚úì Test set:     13,345 samples

======================================================================
STEP 3: HYPERPARAMETER OPTIMIZATION
======================================================================

Constraints:
  ‚Ä¢ n_estimators = 40 (FIXED from research paper)
  ‚Ä¢ Optimization target: Minimize MAE

Search Space:
  ‚Ä¢ max_depth: [3, 4, 5]
  ‚Ä¢ learning_rate: [0.01, 0.05, 0.1]
  ‚Ä¢ subsample: [0.7, 0.8, 0.9]
  ‚Ä¢ colsample_bytree: [0.7, 0.8, 0.9, 1.0]
  ‚Ä¢ min_child_weight: [1, 3, 5]
  ‚Ä¢ gamma: [0, 0.1, 0.2]
  ‚Ä¢ reg_alpha: [0, 0.01, 0.1]
  ‚Ä¢ reg_lambda: [1, 1.5, 2]

RandomizedSearchCV Configuration:
  ‚Ä¢ Cross-validation: 5-fold
  ‚Ä¢ Iterations: 10
  ‚Ä¢ Scoring: neg_mean_absolute_error
  ‚Ä¢ Parallel jobs: All CPU cores

üöÄ Starting optimization...
   This may take several minutes for 70k samples...

Fitting 5 folds for each of 10 candidates, totalling 50 fits

======================================================================
OPTIMIZATION COMPLETE ‚úì
======================================================================

Best Hyperparameters Found:
  ‚Ä¢ subsample: 0.8
  ‚Ä¢ reg_lambda: 1
  ‚Ä¢ reg_alpha: 0.01
  ‚Ä¢ min_child_weight: 5
  ‚Ä¢ max_depth: 4
  ‚Ä¢ learning_rate: 0.1
  ‚Ä¢ gamma: 0.1
  ‚Ä¢ colsample_bytree: 0.9

Best CV MAE (5-fold): 28.77 lbs (13.05 kg)

======================================================================
STEP 4: MODEL EVALUATION
======================================================================

======================================================================
PERFORMANCE COMPARISON: PAPER BASELINE vs. OPTIMIZED MODEL
======================================================================

Metric                         Paper Baseline       Optimized Model      Improvement
----------------------------------------------------------------------
MAE (kg)                       13.50                13.09                ‚úì 3.0% better
MAE (lbs)                      29.76                28.86               
RMSE (kg)                      N/A                  17.07               
R¬≤ Score                       N/A                  0.0243              
======================================================================

üìä Training MAE: 28.63 lbs (12.99 kg)
üìä Test MAE:     28.86 lbs (13.09 kg)

======================================================================
STEP 5: SHAP EXPLAINABILITY ANALYSIS
======================================================================

Initializing SHAP TreeExplainer...
Calculating SHAP values for test set...
  Test samples: 13,345
  ‚úì SHAP values calculated

üìä Generating SHAP Summary Plot (Beeswarm)...
  ‚úì Saved: shap_summary.png

üîç FAILURE ANALYSIS: Examining Top 3 Worst Predictions
----------------------------------------------------------------------

Top 3 Prediction Errors:
Rank   True Weight     Predicted       Error (lbs)     Error (kg)
----------------------------------------------------------------------
1      475.00          186.45          288.55          130.89
2      475.00          193.58          281.42          127.65
3      456.00          198.20          257.80          116.94

üìä Generating SHAP Force Plots for failure cases...
  ‚úì Saved: shap_force_error_1.png
  ‚úì Saved: shap_force_error_2.png
  ‚úì Saved: shap_force_error_3.png

üßπ Cleaning up SHAP objects from memory...
  ‚úì Memory cleanup complete

======================================================================
üéâ OPTIMIZATION COMPLETE!
======================================================================

üìà Results Summary:
  ‚Ä¢ Optimized Test MAE: 13.09 kg
  ‚Ä¢ Paper Baseline MAE: 13.50 kg
  ‚Ä¢ ‚úì IMPROVEMENT: 3.0% better than baseline!

  ‚Ä¢ Test RMSE: 17.07 kg
  ‚Ä¢ Test R¬≤: 0.0243

üìÅ Generated Outputs:
  ‚Ä¢ shap_summary.png
  ‚Ä¢ shap_force_error_1.png
  ‚Ä¢ shap_force_error_2.png
  ‚Ä¢ shap_force_error_3.png

‚úÖ All visualizations saved at 300 DPI
‚úÖ Model ready for deployment or further analysis

======================================================================
